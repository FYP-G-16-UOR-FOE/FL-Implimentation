{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6AmXMJSK4ir",
        "outputId": "567c02f7-590a-4a48-c2a7-bac27fb26852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3gj1CogJsW4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from functools import reduce\n",
        "import math\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 1. Data Loading (from loadDataSet.ipynb)\n",
        "# -------------------------------------------------------------------\n",
        "# Copy-paste or import this function from your notebook\n",
        "def load_data_from_disk(partition_id: int, only_server_test_data: bool = False):\n",
        "    import torchvision\n",
        "    from torch.utils.data import DataLoader\n",
        "    save_dir = \"/content/drive/MyDrive/client_data_backup2\"\n",
        "    BATCH_SIZE = 64\n",
        "\n",
        "    if only_server_test_data:\n",
        "        testset = torchvision.datasets.CIFAR10(\n",
        "            root='./data', train=False, download=True,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "            ])\n",
        "        )\n",
        "        return DataLoader(testset, batch_size=BATCH_SIZE, num_workers=8)\n",
        "\n",
        "    client_filenames = [\n",
        "        os.path.join(save_dir, f'client_{partition_id}.pt.gz'),\n",
        "        os.path.join(save_dir, f'iid_clients_{partition_id}.pt.gz')\n",
        "    ]\n",
        "    for path in client_filenames:\n",
        "        if os.path.exists(path):\n",
        "            partition_data_path = path\n",
        "            break\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No data file for client {partition_id}\")\n",
        "\n",
        "    with gzip.open(partition_data_path, 'rb') as f:\n",
        "        device_data = torch.load(f, map_location='cpu')\n",
        "    device_data = [(x.to(torch.float32), y) for x,y in device_data]\n",
        "    np.random.shuffle(device_data)\n",
        "    split = int(len(device_data)*0.8)\n",
        "    train_data, test_data = device_data[:split], device_data[split:]\n",
        "\n",
        "    normalize = transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    train_data = [(normalize(x), y) for x,y in train_data]\n",
        "    test_data  = [(normalize(x), y) for x,y in test_data]\n",
        "\n",
        "    trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "    valloader  = DataLoader(test_data,  batch_size=BATCH_SIZE, num_workers=1)\n",
        "    return trainloader, valloader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [1]\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 2. QILSA Mask Generation Parameters & Utilities\n",
        "# -------------------------------------------------------------------\n",
        "# Ring dimension and modulus\n",
        "N = 1024\n",
        "q = 12289\n",
        "sigma = 8/np.sqrt(2*np.pi)\n",
        "\n",
        "def sample_A():\n",
        "    \"\"\"Sample public matrix A ∈ R_q^{N×N} uniformly.\"\"\"\n",
        "    return np.random.randint(0, q, size=(N, N), dtype=np.int64)\n",
        "\n",
        "A = sample_A()\n",
        "\n",
        "def sample_gaussian(size):\n",
        "    \"\"\"Discrete Gaussian sampler mod q.\"\"\"\n",
        "    return np.round(np.random.normal(scale=sigma, size=size)).astype(np.int64) % q\n",
        "\n",
        "def ring_mul(a, b):\n",
        "    \"\"\"\n",
        "    Multiply two polynomials a, b in R_q[x]/(x^N + 1).\n",
        "    Naive convolution with wrap-around and sign flip.\n",
        "    \"\"\"\n",
        "    res = np.zeros(N, dtype=np.int64)\n",
        "    for i in range(N):\n",
        "        ai = a[i]\n",
        "        if ai == 0: continue\n",
        "        # direct convolution\n",
        "        res[:N-i] = (res[:N-i] + ai * b[i:]) % q\n",
        "        # wrap-around term (x^N = -1)\n",
        "        res[N-i:] = (res[N-i:] - ai * b[:i]) % q\n",
        "    return res"
      ],
      "metadata": {
        "id": "P_e_p0txLBqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [2]\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 3. Verifiable Secret Sharing (Shamir over large prime)\n",
        "# -------------------------------------------------------------------\n",
        "P = 2**61 - 1  # prime for VSS\n",
        "\n",
        "def _eval_poly(coeffs, x):\n",
        "    res = 0\n",
        "    for c in reversed(coeffs):\n",
        "        res = (res * x + c) % P\n",
        "    return res\n",
        "\n",
        "def share_secret(secret, n, t):\n",
        "    \"\"\"\n",
        "    Split integer `secret` into n Shamir shares with threshold t.\n",
        "    Returns list of (i, share_i).\n",
        "    \"\"\"\n",
        "    coeffs = [secret] + [random.randrange(0, P) for _ in range(t-1)]\n",
        "    return [(i, _eval_poly(coeffs, i)) for i in range(1, n+1)]\n",
        "\n",
        "def lagrange_interpolate_zero(shares):\n",
        "    \"\"\"\n",
        "    Reconstruct f(0) from at least t shares via Lagrange interpolation.\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    for j, yj in shares:\n",
        "        num, den = 1, 1\n",
        "        for m, _ in shares:\n",
        "            if m != j:\n",
        "                num = (num * -m) % P\n",
        "                den = (den * (j - m)) % P\n",
        "        total = (total + yj * num * pow(den, P-2, P)) % P\n",
        "    return total"
      ],
      "metadata": {
        "id": "gOgTqxlALJtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 4. Model & Parameter Vector Helpers\n",
        "# -------------------------------------------------------------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*8*8,128), nn.ReLU(),\n",
        "            nn.Linear(128,10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.conv(x))\n",
        "\n",
        "def get_model_vector(model):\n",
        "    return torch.cat([p.data.view(-1) for p in model.parameters()]).cpu().numpy().astype(np.int64) % q\n",
        "\n",
        "def set_model_vector(model, vec):\n",
        "    pointer = 0\n",
        "    for p in model.parameters():\n",
        "        numel = p.numel()\n",
        "        part = vec[pointer:pointer+numel].reshape(p.shape)\n",
        "        p.data.copy_(torch.from_numpy(part).to(p.dtype))\n",
        "        pointer += numel"
      ],
      "metadata": {
        "id": "MIYCjs1vLTE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 5. Federated Client Implementation\n",
        "# -------------------------------------------------------------------\n",
        "class FedClient:\n",
        "    def __init__(self, client_id, global_model):\n",
        "        self.id = client_id\n",
        "        self.device = torch.device('cpu')\n",
        "        self.trainloader, _ = load_data_from_disk(client_id, False)\n",
        "        self.valloader = load_data_from_disk(0, True)\n",
        "        self.model = SimpleCNN().to(self.device)\n",
        "        self.model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Compute accuracy on this client’s validation set.\"\"\"\n",
        "        correct, total = 0, 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in self.valloader:\n",
        "                out = self.model(x)\n",
        "                _, pred = torch.max(out, dim=1)\n",
        "                correct += (pred == y).sum().item()\n",
        "                total   += y.size(0)\n",
        "        acc = 100 * correct / total\n",
        "        print(f\" Client {self.id} validation accuracy: {acc:.2f}%\")\n",
        "        return acc\n",
        "\n",
        "    def local_train(self, epochs=6, lr=0.01):\n",
        "        optim_ = optim.SGD(self.model.parameters(), lr=lr)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        print(f\"Client {self.id} training...\")\n",
        "        self.model.train()\n",
        "        for _ in range(epochs):\n",
        "            for x,y in self.trainloader:\n",
        "                x,y = x.to(self.device), y.to(self.device)\n",
        "                optim_.zero_grad()\n",
        "                loss_fn(self.model(x), y).backward()\n",
        "                optim_.step()\n",
        "\n",
        "    def get_update(self, global_vec):\n",
        "        local_vec = get_model_vector(self.model)\n",
        "        return (local_vec - global_vec) % q\n",
        "\n",
        "    def generate_mask(self):\n",
        "        \"\"\"\n",
        "        QILSA mask: sample s,e ∈ R_q^N; compute m = A s + e mod q.\n",
        "        \"\"\"\n",
        "        self.s = sample_gaussian(N)\n",
        "        self.e = sample_gaussian(N)\n",
        "        As = np.zeros(N, dtype=np.int64)\n",
        "        for row in range(N):\n",
        "            As = (As + ring_mul(A[row], self.s)) % q\n",
        "        self.mask_poly = (As + self.e) % q\n",
        "\n",
        "    def generate_vss_shares(self, selected_ids, t):\n",
        "        \"\"\"\n",
        "        Shamir-share a random scalar r_i among selected clients.\n",
        "        \"\"\"\n",
        "        self.r = random.randrange(0, P)\n",
        "        shares = share_secret(self.r, len(selected_ids), t)\n",
        "        self.shares = { selected_ids[i]: shares[i][1]\n",
        "                        for i in range(len(selected_ids)) }\n",
        "\n",
        "    def mask_update(self, update_vec):\n",
        "        \"\"\"\n",
        "        Mask the flattened update: break into blocks of size N,\n",
        "        add mask_poly to each block, then add Shamir r across all coords.\n",
        "        \"\"\"\n",
        "        d = update_vec.shape[0]\n",
        "        blocks = int(np.ceil(d / N))\n",
        "        padded = np.zeros(blocks * N, dtype=np.int64)\n",
        "        padded[:d] = update_vec % q\n",
        "\n",
        "        for b in range(blocks):\n",
        "            start,end = b*N, (b+1)*N\n",
        "            padded[start:end] = (padded[start:end] + self.mask_poly) % q\n",
        "\n",
        "        # also tile the scalar r (mod P) into the same shape for server VSS\n",
        "        return padded[:d], self.r"
      ],
      "metadata": {
        "id": "ouEUiX6dLaFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 6. Federated Server Implementation\n",
        "# -------------------------------------------------------------------\n",
        "class FedServer:\n",
        "    def __init__(self, num_clients=50, local_epochs=6,\n",
        "                 rounds=10, threshold=None):\n",
        "        self.global_model = SimpleCNN()\n",
        "        self.num_clients = num_clients\n",
        "        self.local_epochs = local_epochs\n",
        "        self.rounds = rounds\n",
        "        self.clients = list(range(num_clients))\n",
        "        self.threshold = threshold or num_clients\n",
        "        self.testloader = load_data_from_disk(0, True)\n",
        "\n",
        "    def select_clients(self):\n",
        "        # full participation\n",
        "        return random.sample(self.clients, k=5)\n",
        "\n",
        "    def aggregate_round(self):\n",
        "        print(\"Aggregating round...\")\n",
        "        selected = self.select_clients()\n",
        "        t = self.threshold\n",
        "\n",
        "        # 1) Each client trains, masks, and Shamir-shares\n",
        "        globals_vec = get_model_vector(self.global_model)\n",
        "        client_objs = []\n",
        "        masked_updates = []\n",
        "        sum_shares = {cid: 0 for cid in selected}\n",
        "\n",
        "        for cid in selected:\n",
        "            c = FedClient(cid, self.global_model)\n",
        "            c.local_train(self.local_epochs)\n",
        "            c.validate()\n",
        "            c.generate_mask()\n",
        "            c.generate_vss_shares(selected, t)\n",
        "\n",
        "            update = c.get_update(globals_vec)\n",
        "            masked_u, _ = c.mask_update(update)\n",
        "            masked_updates.append(masked_u)\n",
        "\n",
        "            # accumulate each client's share\n",
        "            for partner, share_val in c.shares.items():\n",
        "                sum_shares[partner] = (sum_shares[partner] + share_val) % P\n",
        "\n",
        "            client_objs.append(c)\n",
        "\n",
        "        # 2) Server sums masked updates (mod q)\n",
        "        summed_masked = reduce(lambda a,b: (a+b)%q, masked_updates)\n",
        "\n",
        "        # 3) Server collects t Shamir shares to reconstruct R_sum\n",
        "        share_items = list(sum_shares.items())[:t]\n",
        "        R_sum = lagrange_interpolate_zero(share_items)\n",
        "\n",
        "        # 4) Unmask scalar part (mod P), then remove QILSA mask\n",
        "        #    first remove Shamir sum (tile removal)\n",
        "        unsharded = (summed_masked - (R_sum % q)) % q\n",
        "        # 2) Tile the QILSA mask to length d before subtraction\n",
        "        total_mask = sum(c.mask_poly for c in client_objs) % q  # shape: (N,)\n",
        "        d           = unsharded.shape[0]\n",
        "        blocks      = math.ceil(d / N)\n",
        "        padded_mask = np.tile(total_mask, blocks)[:d]         # shape: (d,)\n",
        "\n",
        "        #    next, subtract sum of all QILSA masks:\n",
        "        #    ∑m_i = A ∑s_i + ∑e_i  (we don't implement lattice decode here;\n",
        "        #    instead we assume server knows ∑mask_poly if needed)\n",
        "        # For simplicity, assume error small enough to round:\n",
        "        #    total_mask = sum(c.mask_poly for c in client_objs) % q\n",
        "        # 3) Unmask element‐wise\n",
        "        unmasked = (unsharded - padded_mask) % q\n",
        "\n",
        "        # 5) Update global model\n",
        "        set_model_vector(self.global_model, unmasked)\n",
        "    def evaluate_global(self):\n",
        "        \"\"\"Compute accuracy of self.global_model on server test set.\"\"\"\n",
        "        correct, total = 0, 0\n",
        "        self.global_model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in self.testloader:\n",
        "                out = self.global_model(x)\n",
        "                _, pred = torch.max(out, dim=1)\n",
        "                correct += (pred == y).sum().item()\n",
        "                total   += y.size(0)\n",
        "        acc = 100 * correct / total\n",
        "        print(f\" Global model test accuracy: {acc:.2f}%\")\n",
        "        return acc\n",
        "\n",
        "    def train(self):\n",
        "        for rnd in range(1, self.rounds+1):\n",
        "            print(f\"--- Global Round {rnd} ---\")\n",
        "            self.aggregate_round()\n",
        "            self.evaluate_global()\n",
        "        print(\"Federated training complete.\")\n"
      ],
      "metadata": {
        "id": "LZCySsVSLhBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------\n",
        "# 7. Run\n",
        "# -------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    server = FedServer(\n",
        "        num_clients=50,\n",
        "        local_epochs=6,\n",
        "        rounds=2,\n",
        "        threshold=2\n",
        "    )\n",
        "    server.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4FmbmPILmJa",
        "outputId": "0c26e50e-1162-4f19-ad2b-5cb3a33d8cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Global Round 1 ---\n",
            "Aggregating round...\n",
            "Client 17 training...\n",
            " Client 17 validation accuracy: 16.95%\n",
            "Client 40 training...\n",
            " Client 40 validation accuracy: 24.05%\n",
            "Client 2 training...\n",
            " Client 2 validation accuracy: 11.05%\n",
            "Client 16 training...\n",
            " Client 16 validation accuracy: 16.14%\n",
            "Client 42 training...\n",
            " Client 42 validation accuracy: 22.44%\n",
            " Global model test accuracy: 10.00%\n",
            "--- Global Round 2 ---\n",
            "Aggregating round...\n",
            "Client 36 training...\n",
            " Client 36 validation accuracy: 10.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-e93685e38baf>:20: RuntimeWarning: invalid value encountered in cast\n",
            "  return torch.cat([p.data.view(-1) for p in model.parameters()]).cpu().numpy().astype(np.int64) % q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 training...\n",
            " Client 4 validation accuracy: 10.00%\n",
            "Client 33 training...\n",
            " Client 33 validation accuracy: 10.00%\n",
            "Client 34 training...\n",
            " Client 34 validation accuracy: 10.00%\n",
            "Client 41 training...\n",
            " Client 41 validation accuracy: 10.00%\n",
            " Global model test accuracy: 10.00%\n",
            "Federated training complete.\n"
          ]
        }
      ]
    }
  ]
}